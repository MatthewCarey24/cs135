{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4 Trees and Forests\n",
    "The analysis task, which aims to classify sentiments using bag-of-words features of product reviews, will let you:\n",
    "* get familiar with hyper-parameters of decision trees and ensemble models;\n",
    "* understand the relative strength of trees and ensemble methods;\n",
    "* gain experience of training these models with `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import sklearn.tree\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-v0_8') # pretty matplotlib plots\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set('notebook', font_scale=1.25, style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the HW4 starter code\n",
    "from pretty_print_sklearn_tree import pretty_print_sklearn_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all data from train/valid/test\n",
    "\n",
    "We consider the text sentiment classification task as in Project A where each example is one plain-text online review collect from amazon.com for a consumer product (either a book, a movie, an electronics item, or a kitchen item). Dataset credit: M. Dredze, J. Blitzer, and Fernando Pereira. <https://www.cs.jhu.edu/~mdredze/datasets/sentiment/>\n",
    "\n",
    "\n",
    "Here's an example book review that is a positive sentiment:\n",
    "\n",
    "> This all-Spanish handbook for parents with new babies will prove essential for any concerned about a child's health. \n",
    "\n",
    "Here's one with a negative sentiment\n",
    "\n",
    "> It completely sucked. Very long with nothing to say. Author was proud of his own knowledge of the SCA and Wiccans, and the publishers thought that obviated the need for plot or character development.\n",
    "\n",
    "\n",
    "\n",
    "We have preprocessed this data for you to the *bag-of-words* representation, using a fixed vocabulary of the 7729 most common words provided by the original dataset creators (with some slight modifications by us). The vocabulary includes some *bigrams* (e.g. \"waste_of\") in addition to single words.  In this task, we use binary features indicating whether words are present (1) or absent (0) in the text. \n",
    "\n",
    "Each data subset is provided as a CSV file. In the header, each column name is the word corresponding to the feature: the feature value indicates whether the corresponding word is present (1) or absent (0) in the review. Later, you will show features that are important for the classification task. It means that the words corresponding to these features are informative about class labels.\n",
    "\n",
    "The label is an overall binary rating of the user's feelings about the product (either 'positive' or 'negative'). Our goal is to build a model that can predict the sentiment (positive or negative) from the text alone.\n",
    "\n",
    "We have provided the following:\n",
    "\n",
    "* a training set of 6346 instances\n",
    "* a validation set of 792 instances\n",
    "* a test set of 793 instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO fix to path on your local system\n",
    "DATA_DIR = os.path.join(\"data_product_reviews/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "x_tr_NF.shape: (6346, 7729)\n",
      "y_tr_N.shape : (6346,)\n",
      "mean(y_tr_N) : 0.500\n"
     ]
    }
   ],
   "source": [
    "x_tr_df = pd.read_csv(os.path.join(DATA_DIR, 'x_train.csv.zip'))\n",
    "y_tr_df = pd.read_csv(os.path.join(DATA_DIR, 'y_train.csv'))\n",
    "x_tr_NF = np.minimum(x_tr_df.values, 1.0).copy()\n",
    "y_tr_N = y_tr_df.values[:,0].copy()\n",
    "\n",
    "print(\"Training data\")\n",
    "print(\"x_tr_NF.shape: %s\" % str(x_tr_NF.shape))\n",
    "print(\"y_tr_N.shape : %s\" % str(y_tr_N.shape))\n",
    "print(\"mean(y_tr_N) : %.3f\" % np.mean(y_tr_N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data\n",
      "x_va_TF.shape: (792, 7729)\n",
      "y_va_T.shape : (792,)\n",
      "mean(y_va_T) : 0.490\n"
     ]
    }
   ],
   "source": [
    "x_va_df = pd.read_csv(os.path.join(DATA_DIR, 'x_valid.csv.zip'))\n",
    "y_va_df = pd.read_csv(os.path.join(DATA_DIR, 'y_valid.csv'))\n",
    "\n",
    "x_va_TF = np.minimum(x_va_df.values, 1.0).copy()\n",
    "y_va_T = y_va_df.values[:,0].copy()\n",
    "\n",
    "print(\"Validation data\")\n",
    "print(\"x_va_TF.shape: %s\" % str(x_va_TF.shape))\n",
    "print(\"y_va_T.shape : %s\" % str(y_va_T.shape))\n",
    "print(\"mean(y_va_T) : %.3f\" % np.mean(y_va_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heldout Test data\n",
      "x_te_TF.shape: (793, 7729)\n",
      "y_te_T.shape : (793,)\n",
      "mean(y_te_T) : 0.515\n"
     ]
    }
   ],
   "source": [
    "x_te_df = pd.read_csv(os.path.join(DATA_DIR, 'x_test.csv.zip'))\n",
    "y_te_df = pd.read_csv(os.path.join(DATA_DIR, 'y_test.csv'))\n",
    "\n",
    "x_te_TF = np.minimum(x_te_df.values, 1.0).copy()\n",
    "y_te_T = y_te_df.values[:,0].copy()\n",
    "\n",
    "print(\"Heldout Test data\")\n",
    "print(\"x_te_TF.shape: %s\" % str(x_te_TF.shape))\n",
    "print(\"y_te_T.shape : %s\" % str(y_te_T.shape))\n",
    "print(\"mean(y_te_T) : %.3f\" % np.mean(y_te_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show column names\n",
    "Each column name is a word. A feature value (1 or 0) indicates whether the word is present or absent in the review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "great\n",
      "time\n",
      "book\n",
      "don't\n",
      "work\n",
      "i_have\n",
      "read\n",
      "...\n",
      "never_get\n",
      "i'd_like\n",
      "loves_it\n",
      "an_author\n",
      "nomin\n",
      "could_give\n",
      "bad_but\n",
      "gap\n"
     ]
    }
   ],
   "source": [
    "vocab_list = x_tr_df.columns.tolist()\n",
    "\n",
    "for word in vocab_list[:8]:\n",
    "    print(word)\n",
    "print(\"...\")\n",
    "for word in vocab_list[-8:]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pack training and validation sets into big arrays (so we can use sklearn's hyperparameter search tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "xall_LF = np.vstack([x_tr_NF, x_va_TF])\n",
    "yall_L = np.hstack([y_tr_N, y_va_T])\n",
    "\n",
    "# Create splitter object using Predefined Split\n",
    "# Will be used later by all hyperparameter sear\n",
    "## <a id=\"problem-1\">Problem 1</a>: Decision Trees for Review Classification \n",
    "\n",
    "valid_indicators_L = np.hstack([\n",
    "    -1 * np.ones(y_tr_N.size), # -1 means never include this example in any test split\n",
    "    0  * np.ones(y_va_T.size), #  0 means include in the first test split (we count starting at 0 in python)\n",
    "    ])\n",
    "my_splitter = sklearn.model_selection.PredefinedSplit(valid_indicators_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Train Decision Trees for Sentiment Classification\n",
    "\n",
    "## Implementation A.1 : Train a Simple Tree\n",
    "\n",
    "Train a `DecisionTreeClassifier` with `criterion='gini'`, `max_depth=3`, `min_samples_leaf=1`, `min_samples_split=2` and `random_state=101`.\n",
    "\n",
    "You'll use this simple tree again later (to make Table 3).\n",
    "\n",
    "**TODO**: Fit the tree  on the training set in the next coding cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_tree = sklearn.tree.DecisionTreeClassifier(\n",
    "    criterion='gini', \n",
    "    max_depth=3, min_samples_split=2, min_samples_leaf=1, \n",
    "    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, random_state=101)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, random_state=101)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=101)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "simple_tree.fit(x_te_df, y_te_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Report 1a: Figure 1 in the report\n",
    "\n",
    "Show the ASCII-text representation of your trained decision tree from 1A, by calling the helper function `pretty_print_sklearn_tree` found in the starter code.\n",
    "(Remember when you are reading the printed statements that \"Y\" means the above decision question evaluated to \"yes\" and \"N\" means \"no\".)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The binary tree structure has 15 nodes.\n",
      "- depth   0 has    1 nodes, of which    0 are leaves\n",
      "- depth   1 has    2 nodes, of which    0 are leaves\n",
      "- depth   2 has    4 nodes, of which    0 are leaves\n",
      "- depth   3 has    8 nodes, of which    8 are leaves\n",
      "The decision tree:  (Note: Y = 'yes' to above question; N = 'no')\n",
      "Decision: X['great'] <= 0.50?\n",
      "  Y Decision: X['waste'] <= 0.50?\n",
      "    Y Decision: X['disappoint'] <= 0.50?\n",
      "      Y Leaf: p(y=1 | this leaf) = 0.504 (496 total training examples)\n",
      "      N Leaf: p(y=1 | this leaf) = 0.130 (46 total training examples)\n",
      "    N Decision: X['so-cal'] <= 0.50?\n",
      "      Y Leaf: p(y=1 | this leaf) = 0.000 (36 total training examples)\n",
      "      N Leaf: p(y=1 | this leaf) = 1.000 (1 total training examples)\n",
      "  N Decision: X['bad'] <= 0.50?\n",
      "    Y Decision: X['terribl'] <= 0.50?\n",
      "      Y Leaf: p(y=1 | this leaf) = 0.777 (188 total training examples)\n",
      "      N Leaf: p(y=1 | this leaf) = 0.125 (8 total training examples)\n",
      "    N Decision: X['bought'] <= 0.50?\n",
      "      Y Leaf: p(y=1 | this leaf) = 0.000 (13 total training examples)\n",
      "      N Leaf: p(y=1 | this leaf) = 0.800 (5 total training examples)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO \n",
    "# call pretty_print_sklearn_tree on simple_tree, providing feature_names=vocab_list\n",
    "pretty_print_sklearn_tree(simple_tree, vocab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation A.2: Model Selection\n",
    "\n",
    "Perform a grid search for the hyperparameters of your `DecisionTree` over the following settings:\n",
    "\n",
    "  * `max_depth` in [2, 8, 32, 128]\n",
    "  * `min_samples_leaf` in [1, 3, 9]\n",
    "  * `random_state` in [101]\n",
    "\n",
    "Be sure to use [sklearn.model_selection.GridSearchCV]().\n",
    "\n",
    "Additional requirements (keep all other settings at default values)\n",
    "\n",
    "* Set `scoring='accuracy'`, since our target metric is accuracy\n",
    "* Set `cv=my_splitter` (as in starter code), so you can use the predefined split we defined earlier.\n",
    "* Set `return_train_score=True`, since we want training set scores as well as test set scores\n",
    "* Set `refit=False`, because we only want fits on `x_tr_NF` (for later with table 3)\n",
    "\n",
    "You'll use this \"best\" tree again later (to make Table 3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the default predictor\n",
    "# Any hyperparameters here may be overridden by the hyperparameter grid\n",
    "\n",
    "base_tree = sklearn.tree.DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    min_samples_split=2, min_samples_leaf=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_hyperparameter_grid_by_name = dict(\n",
    "    max_depth=[2, 8, 32, 128],\n",
    "    min_samples_leaf=[1, 3, 9],\n",
    "    random_state = [101],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Build the Grid Search in the next coding cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "\n",
    "tree_grid_searcher = sklearn.model_selection.GridSearchCV(estimator=base_tree, param_grid=tree_hyperparameter_grid_by_name, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Do the search!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_sec = time.time()\n",
    "tree_grid_searcher.fit(xall_LF, yall_L)\n",
    "elapsed_time_sec = time.time() - start_time_sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Move the results of grid search into a nice pandas data frame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search of  12 configurations done after 49971.2 sec\n"
     ]
    }
   ],
   "source": [
    "if hasattr(tree_grid_searcher, 'cv_results_'):\n",
    "    # Will be here if you called fit on tree_grid_searcher succesfully\n",
    "    tree_search_results_df = pd.DataFrame(tree_grid_searcher.cv_results_).copy()\n",
    "    print(\"Grid search of %3d configurations done after %6.1f sec\" % (\n",
    "        tree_search_results_df.shape[0], elapsed_time_sec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display search results.** This block will make a pretty printed table of the results of your grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(tree_grid_searcher, 'cv_results_'):\n",
    "    pd.set_option('display.precision', 4)\n",
    "    tree_keys = ['param_max_depth', 'param_min_samples_leaf']\n",
    "    tree_search_results_df.sort_values(tree_keys, inplace=True)\n",
    "    tree_search_results_df[tree_keys + ['mean_test_score', 'rank_test_score', 'mean_fit_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a dict of the best hyperparameters\n",
      "{'max_depth': 128, 'min_samples_leaf': 9, 'random_state': 101}\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing a dict of the best hyperparameters\")\n",
    "try:\n",
    "    print(tree_grid_searcher.best_params_)\n",
    "except AttributeError:\n",
    "    print(\"TODO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation A.3: Build the Best Decision Tree\n",
    "\n",
    "**TODO Build the Best Tree on the training set** in the next coding cell. This is necessary so you have the specific best performing tree in your workspace. Although you fit many trees in the search, they were not stored, so we need to recreate the best one. Hint: Just feed the best hyperparameters as keyword args to construct the tree and fit it to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=128, min_samples_leaf=9, random_state=101)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=128, min_samples_leaf=9, random_state=101)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=128, min_samples_leaf=9, random_state=101)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree = base_tree.set_params(max_depth = 128, min_samples_leaf = 9, random_state = 101) # TODO call set_params using the best_params_ found by your searcher\n",
    "best_tree.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Report 1b: short answers to the following two questions\n",
    "\n",
    "* What are the `max_depth` and `min_samples_leaf` of the best tree?\n",
    "* How should we change `min_samples_leaf` if we want to reduce overfitting? Please explain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report 1c: plot the best decision tree\n",
    "\n",
    "Please include the plot of the best decision tree in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search of  16 configurations done after  148.8 sec\n",
      "Printing a dict of the best hyperparameters\n",
      "{'max_depth': 3, 'min_samples_leaf': 27, 'min_samples_split': 0.04, 'random_state': 101}\n"
     ]
    }
   ],
   "source": [
    "c_tree = sklearn.tree.DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "c_tree_hyperparameter_grid_by_name = dict(\n",
    "    max_depth=[3],\n",
    "    min_samples_leaf=[1, 3, 9, 27],\n",
    "    min_samples_split = [0.01, 0.04, 0.08, 0.16],\n",
    "    random_state = [101],\n",
    "    )\n",
    "\n",
    "import sklearn.model_selection\n",
    "\n",
    "c_tree_grid_searcher = sklearn.model_selection.GridSearchCV(estimator=c_tree, param_grid=c_tree_hyperparameter_grid_by_name, scoring='roc_auc')\n",
    "\n",
    "start_time_sec = time.time()\n",
    "c_tree_grid_searcher.fit(xall_LF, yall_L)\n",
    "elapsed_time_sec = time.time() - start_time_sec\n",
    "\n",
    "if hasattr(tree_grid_searcher, 'cv_results_'):\n",
    "    # Will be here if you called fit on tree_grid_searcher succesfully\n",
    "    c_tree_search_results_df = pd.DataFrame(c_tree_grid_searcher.cv_results_).copy()\n",
    "    print(\"Grid search of %3d configurations done after %6.1f sec\" % (\n",
    "        c_tree_search_results_df.shape[0], elapsed_time_sec))\n",
    "    \n",
    "print(\"Printing a dict of the best hyperparameters\")\n",
    "try:\n",
    "    print(c_tree_grid_searcher.best_params_)\n",
    "except AttributeError:\n",
    "    print(\"TODO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The binary tree structure has 13 nodes.\n",
      "- depth   0 has    1 nodes, of which    0 are leaves\n",
      "- depth   1 has    2 nodes, of which    0 are leaves\n",
      "- depth   2 has    4 nodes, of which    1 are leaves\n",
      "- depth   3 has    6 nodes, of which    6 are leaves\n",
      "The decision tree:  (Note: Y = 'yes' to above question; N = 'no')\n",
      "Decision: X['great'] <= 0.50?\n",
      "  Y Decision: X['excel'] <= 0.50?\n",
      "    Y Decision: X['disappoint'] <= 0.50?\n",
      "      Y Leaf: p(y=1 | this leaf) = 0.430 (4041 total training examples)\n",
      "      N Leaf: p(y=1 | this leaf) = 0.114 (368 total training examples)\n",
      "    N Decision: X['it_was'] <= 0.50?\n",
      "      Y Leaf: p(y=1 | this leaf) = 0.905 (263 total training examples)\n",
      "      N Leaf: p(y=1 | this leaf) = 0.643 (28 total training examples)\n",
      "  N Decision: X['return'] <= 0.50?\n",
      "    Y Decision: X['bad'] <= 0.50?\n",
      "      Y Leaf: p(y=1 | this leaf) = 0.745 (1413 total training examples)\n",
      "      N Leaf: p(y=1 | this leaf) = 0.415 (142 total training examples)\n",
      "    N Leaf: p(y=1 | this leaf) = 0.275 (91 total training examples)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_c_tree = c_tree.set_params(max_depth = 3, min_samples_leaf = 27, min_samples_split = 0.04, random_state = 101) # TODO call set_params using the best_params_ found by your searcher\n",
    "best_c_tree.fit(x_tr_NF, y_tr_N)\n",
    "    \n",
    "if hasattr(tree_grid_searcher, 'cv_results_'):\n",
    "    pd.set_option('display.precision', 4)\n",
    "    c_tree_keys = ['param_max_depth', 'param_min_samples_leaf']\n",
    "    c_tree_search_results_df.sort_values(c_tree_keys, inplace=True)\n",
    "    c_tree_search_results_df[c_tree_keys + ['mean_test_score', 'rank_test_score', 'mean_fit_time']]\n",
    "pretty_print_sklearn_tree(best_c_tree, feature_names=vocab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report 1d: a short Answer 1b in Report\n",
    "\n",
    "Reflect on the two trees plotted. Remember that we are predicting overall sentiment about a product based on observed words in a written review.\n",
    "\n",
    "* Is there any internal node that has two child leaf nodes corresponding to the same sentiment class? If so, why would having two children predict the same class make sense? (Hint: do the two child leaves have the same output in the printout? What does this have to do with gini impurity?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Training a Random Forest for Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An example tabl** \n",
    "\n",
    "|**Important Words**|**Unimportant Words**|\n",
    "|:-:|:-:|\n",
    "|I1 |  U1  |\n",
    "|I2 |  U2  |\n",
    "|I3 |  U3  |\n",
    "|I4 |  U4  |\n",
    "|I5 |  U5  |\n",
    "|I6 |  U6  |\n",
    "|I7 |  U7  |\n",
    "|I8 |  U8  |\n",
    "|I9 |  U9  |\n",
    "|I0 |  U0  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation B.1: Find good hyperparameters for a Random Forest via grid search\n",
    "\n",
    "Follow the instructions and use what you learn in Problem 1 to finish this step. This block might take 2-10 minutes. (Takes about 2 min on staff Macbook laptops.) If yours runs significantly longer, try this out on Google Colab instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_forest = sklearn.ensemble.RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='gini',\n",
    "    max_depth=16,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_hyperparameter_grid_by_name = dict(\n",
    "    max_features=[3, 10, 33, 100, 333],\n",
    "    max_depth=[16, 32],\n",
    "    min_samples_leaf=[1],\n",
    "    n_estimators=[100],\n",
    "    random_state=[101],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO construct a GridSearchCV object like you did above.\n",
    "\n",
    "forest_searcher = sklearn.model_selection.GridSearchCV(estimator=base_forest, param_grid=forest_hyperparameter_grid_by_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Do the search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "start_time_sec = time.time()\n",
    "forest_searcher.fit(xall_LF, yall_L)\n",
    "elapsed_time_sec = time.time() - start_time_sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Build dataframe of results. You can reuse the code from Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search of  10 configurations done after  416.9 sec\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "if hasattr(forest_searcher, 'cv_results_'):\n",
    "    # Will be here if you called fit on forest_searcher succesfully\n",
    "    forest_search_results_df = pd.DataFrame(forest_searcher.cv_results_).copy()\n",
    "    print(\"Grid search of %3d configurations done after %6.1f sec\" % (\n",
    "        forest_search_results_df.shape[0], elapsed_time_sec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Display search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a dict of the best hyperparameters\n",
      "{'max_depth': 32, 'max_features': 33, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': 101}\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "if hasattr(forest_searcher, 'cv_results_'):\n",
    "    pd.set_option('display.precision', 4)\n",
    "    forest_keys = ['param_max_features', 'param_max_depth', 'param_min_samples_leaf', 'param_n_estimators']\n",
    "    forest_search_results_df.sort_values(forest_keys, inplace=True)\n",
    "    forest_search_results_df[forest_keys + ['mean_test_score', 'rank_test_score', 'mean_fit_time']]\n",
    "\n",
    "print(\"Printing a dict of the best hyperparameters\")\n",
    "try:\n",
    "    print(forest_searcher.best_params_)\n",
    "except AttributeError:\n",
    "    print(\"TODO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation B.2: Build the best random forest using the best hyperparameters found in B.1 \n",
    "\n",
    "This is necessary so you have the specific best performing forest in your workspace.\n",
    "\n",
    "Train *only* on training set (do not merge train and valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=32, max_features=33, random_state=101)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=32, max_features=33, random_state=101)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=32, max_features=33, random_state=101)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO\n",
    "best_forest = base_forest.set_params(max_depth = 32, max_features = 33, min_samples_leaf = 1, n_estimators = 100, random_state = 101) # TODO call set_params using the best_params_ found by your searcher\n",
    "best_forest.fit(x_tr_NF, y_tr_N)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation B.3: Compute feature importances from the trained random forest\n",
    "\n",
    "\n",
    "Please check <https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html>. We did not talk about feature importances in the class, but this is an important concept for you to learn. It is easy to compute feature importances with `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute the importances: 0.017 seconds\n",
      "    Top Words   Bottom Words\n",
      "0     easy_to      first_few\n",
      "1       worst    years_after\n",
      "2        poor      always_be\n",
      "3        love       me_about\n",
      "4       excel          domin\n",
      "5       great  several_other\n",
      "6  disappoint      the_night\n",
      "7         bad        you_had\n",
      "8      return   toaster_oven\n",
      "9       waste       right_to\n",
      "Words with importance below threshold:  791\n"
     ]
    }
   ],
   "source": [
    "# TODO Compute feature importances here. \n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "start_time = time.time()\n",
    "importances = best_forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in best_forest.estimators_], axis=0)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
    "\n",
    "# Sort the feature importances and get the indices\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "\n",
    "\n",
    "# Get the top 10 most important and least important features\n",
    "top_indices = indices[-10:]\n",
    "bottom_indices = indices[:10]\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "data = {\n",
    "    'Top Words': [vocab_list[i] for i in top_indices],\n",
    "    'Bottom Words': [vocab_list[i] for i in bottom_indices],\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "threshold = 0.00001\n",
    "count_low_importance = sum(imp < threshold for imp in importances)\n",
    "print(\"Words with importance below threshold: \", count_low_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report 2a: Show important and unimportant words in the classification task \n",
    "\n",
    "Please read this page <https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html> to understand feature importances. You need to create a table and show 10 important words and 10 unimportant words. You can show a few more if you find the results interesting. \n",
    "\n",
    "An example table is shown below. The table has 2 panels, with the left one displaying 10 vocabulary words with *highest* feature importance, and the right one displaying 10 randomly chosen terms that have *close-to-zero* feature importance (any feature with importance less than 0.00001 is eligible). For the latter one, **Be sure to indicate how many 'eligible' features these 10 were chosen from.**\n",
    "\n",
    "*Hint*: useful functions: `numpy.argsort`, `numpy.flatnonzero`, `numpy.abs`. There is a sample output in the Jupyter notebook.\n",
    "\n",
    "**No caption is needed**. But we do encourage you to reflect for your own learning: do the top-ranked words seem important to your own human judgment? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An example table** \n",
    "\n",
    "|**Important Words**|**Unimportant Words**|\n",
    "|:-:|:-:|\n",
    "|I1 |  U1  |\n",
    "|I2 |  U2  |\n",
    "|I3 |  U3  |\n",
    "|I4 |  U4  |\n",
    "|I5 |  U5  |\n",
    "|I6 |  U6  |\n",
    "|I7 |  U7  |\n",
    "|I8 |  U8  |\n",
    "|I9 |  U9  |\n",
    "|I10 |  U10  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report 2b: A short answer to the following questions\n",
    "\n",
    "* What is the best hyper-parameter combination from your search?\n",
    "* What is the maximum value `max_features` could take for this dataset?\n",
    "* Why do we want to tune `max_features` instead of setting it to its max possible value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report 2c: A short answer to the following questions\n",
    "\n",
    "When you fit random forests, you can adjust `n_estimators` to set the number of trees in your ensemble.\n",
    "\n",
    "* What is the primary tradeoff this hyperparameter controls? \n",
    "* Can you overfit by setting this too large? Why or why not? You may need to experiment with this hyper-parameter to answer the question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Train a GBDT for Sentiment Classification\n",
    "\n",
    "\n",
    "We'll now try another kind of *ensemble* method: Gradient Boosting to improve the performance for Decision Trees on our classification problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation C.1: Best GBDT via grid search\n",
    "\n",
    "This step is similar to previous model selection. This block might take several minutes. If yours runs significantly longer, try this out on Google Colab instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_gbdt = sklearn.ensemble.GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='friedman_mse',\n",
    "    max_depth=16,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this is the recommended search range. You can choose to make some adjustments so \n",
    "# that the best model is not on the \"boundary\" of the search range. \n",
    "\n",
    "gbdt_hyperparameter_grid_by_name = dict(\n",
    "    max_features=[3],\n",
    "    max_depth=[4, 8, 16, 32],\n",
    "    learning_rate=[0.1, 0.01, 0.001],\n",
    "    n_estimators=[100, 200, 300],\n",
    "    random_state=[101],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO construct a GridSearchCV object like you did above.\n",
    "\n",
    "gbdt_searcher = sklearn.model_selection.GridSearchCV(estimator=base_gbdt, param_grid=gbdt_hyperparameter_grid_by_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: do the search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "start_time_sec = time.time()\n",
    "gbdt_searcher.fit(xall_LF, yall_L)\n",
    "elapsed_time_sec = time.time() - start_time_sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Build dataframe of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search of  36 configurations done after  390.3 sec\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "if hasattr(gbdt_searcher, 'cv_results_'):\n",
    "    # Will be here if you called fit on forest_searcher succesfully\n",
    "    gbdt_search_results_df = pd.DataFrame(gbdt_searcher.cv_results_).copy()\n",
    "    print(\"Grid search of %3d configurations done after %6.1f sec\" % (\n",
    "        gbdt_search_results_df.shape[0], elapsed_time_sec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Display search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a dict of the best hyperparameters\n",
      "{'learning_rate': 0.01, 'max_depth': 32, 'max_features': 3, 'n_estimators': 300, 'random_state': 101}\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "if hasattr(gbdt_searcher, 'cv_results_'):\n",
    "    pd.set_option('display.precision', 4)\n",
    "    gbdt_keys = ['param_max_features','param_max_depth','param_learning_rate','param_n_estimators','param_random_state']\n",
    "    gbdt_search_results_df.sort_values(gbdt_keys, inplace=True)\n",
    "    gbdt_search_results_df[gbdt_keys + ['mean_test_score', 'rank_test_score', 'mean_fit_time']]\n",
    "\n",
    "print(\"Printing a dict of the best hyperparameters\")\n",
    "try:\n",
    "    print(gbdt_searcher.best_params_)\n",
    "except AttributeError:\n",
    "    print(\"TODO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation C.2: Build the best GBDT using the best hyperparameters found in C.1\n",
    "\n",
    "This is necessary so you have the specific best performing forest in your workspace.\n",
    "\n",
    "Train *only* on training set (do not merge train and valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=0.01, max_depth=32, max_features=3,\n",
       "                           n_estimators=300, random_state=101)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.01, max_depth=32, max_features=3,\n",
       "                           n_estimators=300, random_state=101)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.01, max_depth=32, max_features=3,\n",
       "                           n_estimators=300, random_state=101)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO\n",
    "best_gbdt = base_gbdt.set_params(learning_rate = 0.01, max_depth = 32, max_features = 3, n_estimators = 300, random_state = 101) \n",
    "best_gbdt.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report 3a: Short answers to the following questions\n",
    "\n",
    "* What is the best hyper-parameter combination from your search?\n",
    "* Is the hyperparameter `n_estimators` related to overfitting/underfitting behaviors? Please explain.\n",
    "* If we use a shallow tree, which could not fit the data well (high bias). Can GBDT still work? Please explain your answers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report 3b: A short answer to the following question.\n",
    "\n",
    "We are solving a classification problem, but the setting `criterion='friedman_mse'` suggests that some kind of squared error is minimized. Is that weird? Can you resolve this question with a short explanation? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report 3c: Report feature importances\n",
    "\n",
    "Please create a table and show the top 10 and the bottom 10 important words. You can show a few more if you find the results interesting. The table should have the same format as the one in Problem 2. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute the importances: 0.016 seconds\n",
      "    Top Words Bottom Words\n",
      "0        poor          con\n",
      "1     a_great    ending_is\n",
      "2        bore        domin\n",
      "3    the_best      in_just\n",
      "4         bad    one_point\n",
      "5     easy_to       sunday\n",
      "6  disappoint         host\n",
      "7       waste     the_hero\n",
      "8       excel   i_strongly\n",
      "9       great      hold_it\n",
      "Words with importance below threshold:  69\n"
     ]
    }
   ],
   "source": [
    "# TODO Compute feature importances here. \n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "start_time = time.time()\n",
    "importances = best_gbdt.feature_importances_\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
    "\n",
    "# Sort the feature importances and get the indices\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "\n",
    "\n",
    "# Get the top 10 most important and least important features\n",
    "top_indices = indices[-10:]\n",
    "bottom_indices = indices[:10]\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "data = {\n",
    "    'Top Words': [vocab_list[i] for i in top_indices],\n",
    "    'Bottom Words': [vocab_list[i] for i in bottom_indices],\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "threshold = 0.00001\n",
    "count_low_importance = sum(imp < threshold for imp in importances)\n",
    "print(\"Words with importance below threshold: \", count_low_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4: Compare Different Models\n",
    "\n",
    "\n",
    "## Report 4a: Compare accuracies of different models\n",
    "\n",
    "Please report **accuracy values** of the three best models on the train, valid, and test sets, to 3 digits of precision in a table.\n",
    "\n",
    "The table should include 3 rows, one for each model pipeline:\n",
    "\n",
    "* Best decision tree (from 1B)\n",
    "* Best random forest (from 2C)\n",
    "* Best GBDT (from 3C)\n",
    "\n",
    "It should have 5 columns:\n",
    "\n",
    "* col 1 to indicate the *number of trees*\n",
    "* col 2 to indicate the `max_depth` used (or found via search)\n",
    "* col 3-5 report *balanced accuracy* on each dataset (train/valid/test)\n",
    "\n",
    "Include a brief caption summarizing your conclusions: \n",
    "\n",
    "* Which method (which row) does best on the test set?\n",
    "* Does your table's relative ranking of \"best\" tree, \"best\" forest, and \"best\" GBDT agree with course concepts? Why or why not?\n",
    "\n",
    "**Sample Output** (Feel free to print all values and organize them by hand)\n",
    "\n",
    "|**method**|**max depth**|**num trees**|**train BAcc**|**valid BAcc**|**test BAcc**|\n",
    "|:-|:-:|:-:|:-:|:-:|:-:|\n",
    "|best Tree\t|1 | 1 | 0.123\t|0.456\t|0.890|\n",
    "|best RandomForest\t|1 | 1 | 0.123\t|0.456\t|0.890|\n",
    "|best GBDT\t|1 | 1 | 0.123\t|0.456\t|0.890|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carey\\anaconda3\\envs\\cs135_env\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\carey\\anaconda3\\envs\\cs135_env\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\carey\\anaconda3\\envs\\cs135_env\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\carey\\anaconda3\\envs\\cs135_env\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\carey\\anaconda3\\envs\\cs135_env\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\carey\\anaconda3\\envs\\cs135_env\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\carey\\anaconda3\\envs\\cs135_env\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\carey\\anaconda3\\envs\\cs135_env\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\carey\\anaconda3\\envs\\cs135_env\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Method  Max Depth  Num Trees  Train BAcc  Validation BAcc  \\\n",
      "0           Decision Tree        128          1      0.8308           0.7296   \n",
      "1           Random Forest         32          1      0.9690           0.8373   \n",
      "2  Gradient Boosted Trees         32        300      0.9943           0.8487   \n",
      "\n",
      "   Test BAcc  \n",
      "0     0.7127  \n",
      "1     0.8342  \n",
      "2     0.8522  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Assuming you have predictions for training, validation, and test sets for each model\n",
    "# Replace these with your actual predictions\n",
    "# Make sure that your predictions are in the format of true labels and predicted labels\n",
    "\n",
    "# Calculate BAcc scores for training, validation, and test sets for each model\n",
    "best_tree_train_bacc = balanced_accuracy_score(y_tr_df, best_tree.predict(x_tr_df))\n",
    "best_tree_val_bacc = balanced_accuracy_score(y_va_df, best_tree.predict(x_va_df))\n",
    "best_tree_test_bacc = balanced_accuracy_score(y_te_df, best_tree.predict(x_te_df))\n",
    "\n",
    "best_forest_train_bacc = balanced_accuracy_score(y_tr_df, best_forest.predict(x_tr_df))\n",
    "best_forest_val_bacc = balanced_accuracy_score(y_va_df, best_forest.predict(x_va_df))\n",
    "best_forest_test_bacc = balanced_accuracy_score(y_te_df, best_forest.predict(x_te_df))\n",
    "\n",
    "best_gbdt_train_bacc = balanced_accuracy_score(y_tr_df, best_gbdt.predict(x_tr_df))\n",
    "best_gbdt_val_bacc = balanced_accuracy_score(y_va_df, best_gbdt.predict(x_va_df))\n",
    "best_gbdt_test_bacc = balanced_accuracy_score(y_te_df, best_gbdt.predict(x_te_df))\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "data = {\n",
    "    'Method': ['Decision Tree', 'Random Forest', 'Gradient Boosted Trees'],\n",
    "    'Max Depth': [best_tree.max_depth, best_forest.max_depth, best_gbdt.max_depth],\n",
    "    'Num Trees': [1, best_forest.n_estimators, best_gbdt.n_estimators],\n",
    "    'Train BAcc': [best_tree_train_bacc, best_forest_train_bacc, best_gbdt_train_bacc],\n",
    "    'Validation BAcc': [best_tree_val_bacc, best_forest_val_bacc, best_gbdt_val_bacc],\n",
    "    'Test BAcc': [best_tree_test_bacc, best_forest_test_bacc, best_gbdt_test_bacc]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
